<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation | Ayin</title><meta name="author" content="YiZhen"><meta name="copyright" content="YiZhen"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="The cold HR has forged a warm project on my resume">
<meta property="og:type" content="article">
<meta property="og:title" content="Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation">
<meta property="og:url" content="https://ayinzhang.github.io/en/2025/12/19/2025-12-19-Simply%20Exploration%20of%20LLM%20PEFT%20Fine-tuning%20and%20Ollama%20Operation/index.html">
<meta property="og:site_name" content="Ayin">
<meta property="og:description" content="The cold HR has forged a warm project on my resume">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://pic1.zhimg.com/v2-71b0fc16e8b2f0e3771e38494b646666_r.jpg?source=172ae18b">
<meta property="article:published_time" content="2025-12-18T16:00:00.000Z">
<meta property="article:modified_time" content="2026-01-18T07:44:32.125Z">
<meta property="article:author" content="YiZhen">
<meta property="article:tag" content="Artificial intelligence">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic1.zhimg.com/v2-71b0fc16e8b2f0e3771e38494b646666_r.jpg?source=172ae18b"><link rel="shortcut icon" href="https://fastly.jsdelivr.net/gh/ayinzhang/ayinzhang.github.io/img/icon.png"><link rel="canonical" href="https://ayinzhang.github.io/en/2025/12/19/2025-12-19-Simply%20Exploration%20of%20LLM%20PEFT%20Fine-tuning%20and%20Ollama%20Operation/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/en/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?f74029fa7cc77ea7995800ef7950497d";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/en/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"EN","msgToSimplifiedChinese":"ZH"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-01-18 15:44:32'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.2.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/en/img/me.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/en/archives/"><div class="headline">Articles</div><div class="length-num">26</div></a><a href="/en/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/en/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/en/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/en/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/en/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/en/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/en/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="https://ayinzhang.github.io/"><i class="fa-fw fas fa-c"></i><span> Language</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic1.zhimg.com/v2-71b0fc16e8b2f0e3771e38494b646666_r.jpg?source=172ae18b')"><nav id="nav"><span id="blog-info"><a href="/en/" title="Ayin"><span class="site-name">Ayin</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/en/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/en/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/en/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/en/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/en/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/en/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="https://ayinzhang.github.io/"><i class="fa-fw fas fa-c"></i><span> Language</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-12-18T16:00:00.000Z" title="Created 2025-12-19 00:00:00">2025-12-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2026-01-18T07:44:32.125Z" title="Updated 2026-01-18 15:44:32">2026-01-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/en/categories/Technology-Sharing/">Technology Sharing</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/en/categories/Technology-Sharing/AI-related/">AI related</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h3 id="Written-before"><a href="#Written-before" class="headerlink" title="Written before"></a>Written before</h3><p>Over the past few months, I have been mostly occupied with autumn recruitment and my master’s thesis.     Thanks to some guidance from the AIGC engineer who used to sit next to me during my internship, I gained a deeper understanding of AI systems.     Coincidentally, we also got laid off one after another, which, in hindsight, feels oddly amusing.</p>
<p>During the recruitment season, I applied across game programming, design, and art roles.  After being repeatedly “kept in the pipeline” I eventually missed out on my second-choice positions and internal backup opportunities. Ironically, Huawei AI—originally an application I submitted just for fun—progressed surprisingly fast. At that point, the path forward seemed clear enough: pivot into AI during spring recruitment.</p>
<p>Looking back, I realized that I had been overly polite in conversations with HR. If the responses I received were consistently cold and formulaic, why shouldn’t I respond in the same way? That thought quickly turned into action—and thus began the process of turning cold HR replies into a warm project on my resume.</p>
<h3 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h3><h4 id="Preliminary-research"><a href="#Preliminary-research" class="headerlink" title="Preliminary research"></a>Preliminary research</h4><p>In summary, there are four common approaches to controlling LLM output style: Prompt Engineering, Pipeline &#x2F; Process-level Constraints, RAG, Model Fine-tuning. Initial experiments showed that relying solely on prompts lacked stability; in some cases, the model would even refuse tasks due to its built-in politeness or safety alignment. Process-level constraints offer stronger control, but style is difficult to formalize as explicit rules, and evaluating whether an output is “cold and formulaic enough” still requires human judgment.<br> RAG, in my experience, is more suitable for knowledge augmentation. It does not fundamentally override the model’s polite conversational bias. As a result, I ultimately chose PEFT-based fine-tuning, with validation performed using Ollama.</p>
<table>
<thead>
<tr>
<th>Approach</th>
<th>Description</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody><tr>
<td>Prompt Engineering</td>
<td>Uses system or user prompts to explicitly describe desired expression rules and guide generation.</td>
<td>Simple to implement; suitable for rapid prototyping; non-intrusive to the model or deployment.</td>
<td>Limited stability; sensitive to context length; hard to ensure long-term consistency.</td>
</tr>
<tr>
<td>Pipeline Constraints</td>
<td>Introduces fixed processes before or after inference, such as validation or rewriting, to enforce output rules.</td>
<td>Strong controllability; suitable for production; model-agnostic.</td>
<td>Higher system complexity; may reduce naturalness and flexibility.</td>
</tr>
<tr>
<td>RAG</td>
<td>Retrieves example texts and injects them into context to guide stylistic imitation.</td>
<td>Style can be iterated via examples without retraining; more stable than prompts alone.</td>
<td>Dependent on retrieval quality and context length; higher inference cost; indirect control.</td>
</tr>
<tr>
<td>Model Fine-tuning</td>
<td>Trains the model on labeled data to internalize the target style.</td>
<td>Best consistency and stability; natural output; simple inference pipeline.</td>
<td>High data and training cost; low flexibility; style changes require retraining.</td>
</tr>
</tbody></table>
<h4 id="Overall-Architecture"><a href="#Overall-Architecture" class="headerlink" title="Overall Architecture"></a>Overall Architecture</h4><p>Therefore, I first downloaded a 7B+ base model in Safetensors format (models below 7B were noticeably unreliable), performed LoRA fine-tuning, merged the weights, and then converted the result to GGUF using llama.cpp for deployment in Ollama.</p>
<p>The specific process is roughly to load the model, the tokenizer, the training set, and the LoRA adapter to train the model. Then combine the ground modulus and LoRA weights, and convert them to GGUF for storage using LLama.cpp. Due to insufficient GPU memory (bro? I just bought a 12G 5070ti Laptap), I loaded the base mode twice. The first time was after 4-bit quantization and training on the GPU, and the second time was merging on the CPU. Although the cause was his own poverty, it seems that this is also a common practice in industry? (Turns out everyone is equally poor.jpg)”</p>
<h3 id="Practical-Implementation"><a href="#Practical-Implementation" class="headerlink" title="Practical Implementation"></a>Practical Implementation</h3><h4 id="Model-Fine-tuning"><a href="#Model-Fine-tuning" class="headerlink" title="Model Fine-tuning"></a>Model Fine-tuning</h4><p>Logically speaking, the dataset for such a simple task should be around a hundred entries, but manual verification and modification are required. After spending a lot of time, I managed to come up with sixty pieces and stored them at the same level as the training python file under the name train_data.jsonl.</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span><span class="string">&quot;以冷漠、公式化的语气回复HR&quot;</span><span class="punctuation">,</span><span class="attr">&quot;input&quot;</span><span class="punctuation">:</span><span class="string">&quot;这个薪资离我预期差太远了，还能再谈谈吗？&quot;</span><span class="punctuation">,</span><span class="attr">&quot;output&quot;</span><span class="punctuation">:</span><span class="string">&quot;当前薪资方案与个人预期存在较大差异，咨询能否调整。&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>The following is the framework for training the code. The specific steps and intentions have all been annotated in English. What is particularly worth emphasizing and has taken a long time to address is that the training process abnormally terminated during the word segmentation stage. After investigation, it was found that this was not caused by the model or the training parameters themselves, but rather by the mismatch between the data file format and the reading method of the word segmentation device. During the repair phase, individuals thoroughly resolved the related issues by explicitly verifying the integrity of data lines, unifying text encoding and line break rules.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ----------------- 1. Replace the model and configure 4-bit quantization -----------------</span></span><br><span class="line">model_name = <span class="string">&quot;Qwen1.5-7B&quot;</span></span><br><span class="line"><span class="comment"># Configure 4-bit quantization to accommodate low video memory</span></span><br><span class="line">bnb_config = BitsAndBytesConfig()</span><br><span class="line"><span class="comment"># Load the tokenizer and model</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained()</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained()</span><br><span class="line">model = prepare_model_for_kbit_training()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 2. Load and format data -----------------</span></span><br><span class="line">train_dataset = load_and_format_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 3. Tokenize function -----------------</span></span><br><span class="line">tokenized_dataset = train_dataset.<span class="built_in">map</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 4. Configure LoRA -----------------</span></span><br><span class="line">lora_config = LoraConfig()</span><br><span class="line"></span><br><span class="line">model = get_peft_model(); model.print_trainable_parameters()</span><br><span class="line">model.enable_input_require_grads(); model.config.use_cache = <span class="literal">False</span>; model.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 5. Configure training parameters -----------------</span></span><br><span class="line">training_args = TrainingArguments()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 6. Create trainer and train -----------------</span></span><br><span class="line">data_collator = DataCollatorForLanguageModeling()</span><br><span class="line">trainer = Trainer()</span><br><span class="line">trainer.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 7. Save the LoRA adapter -----------------</span></span><br><span class="line">model.save_pretrained()</span><br><span class="line">tokenizer.save_pretrained()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 8. Combine LoRA weight -----------------</span></span><br><span class="line">base_model = AutoModelForCausalLM.from_pretrained()</span><br><span class="line">lora_model = PeftModel.from_pretrained()</span><br><span class="line">merged_model = lora_model.merge_and_unload()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 9. Save the complete model -----------------</span></span><br><span class="line">merged_model_dir = <span class="string">&quot;./merged_full_model&quot;</span></span><br><span class="line">merged_model.save_pretrained()</span><br><span class="line">tokenizer.save_pretrained()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------- 10. Convert to GGUF format(Using llama.cpp) -----------------</span></span><br><span class="line">quantization_type = <span class="string">&quot;q8_0&quot;</span></span><br><span class="line">convert_to_gguf_python()</span><br></pre></td></tr></table></figure>

<h4 id="Runtime-Validation"><a href="#Runtime-Validation" class="headerlink" title="Runtime Validation"></a>Runtime Validation</h4><p>The next step is to import Ollama for testing. Personally, I installed Ollama on a non-system disk (by default, it is installed on the system disk, and the console command “OllamaSetup.exe &#x2F;DIR&#x3D;”YOURDIR” is required), and then created a separate folder” models “in the directory to store the models to be imported. Specifically for individual models, a Modelfile is created to be at the same level as the model’s GGUF. In the Modelfile, the model’s From, Template, and parameters are recorded for easy import. Specific Settings remain in <a target="_blank" rel="noopener" href="https://ollama.com/library">the official document</a> in the template parameters are consistent, here with DeepSeek - R1 first do a demonstration.</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">FROM ./BaseDeepSeek.gguf</span><br><span class="line"></span><br><span class="line">TEMPLATE </span><br><span class="line">&quot;&quot;&quot;&#123;&#123;- if .System &#125;&#125;&#123;&#123; .System &#125;&#125;&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123;- range $i, $_ := .Messages &#125;&#125;</span><br><span class="line">&#123;&#123;- $last := eq (len (slice $.Messages $i)) 1&#125;&#125;</span><br><span class="line">&#123;&#123;- if eq .Role &quot;user&quot; &#125;&#125;&lt;｜User｜&gt;&#123;&#123; .Content &#125;&#125;</span><br><span class="line">&#123;&#123;- else if eq .Role &quot;assistant&quot; &#125;&#125;&lt;｜Assistant｜&gt;</span><br><span class="line">  &#123;&#123;- if and $.IsThinkSet (and $last .Thinking) -&#125;&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">think</span>&gt;</span></span><br><span class="line">&#123;&#123; .Thinking &#125;&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">think</span>&gt;</span></span><br><span class="line">&#123;&#123;- end &#125;&#125;&#123;&#123; .Content &#125;&#125;&#123;&#123;- if not $last &#125;&#125;&lt;｜end▁of▁sentence｜&gt;&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;</span><br><span class="line">&#123;&#123;- if and $last (ne .Role &quot;assistant&quot;) &#125;&#125;&lt;｜Assistant｜&gt;</span><br><span class="line">&#123;&#123;- if and $.IsThinkSet (not $.Think) -&#125;&#125;</span><br><span class="line"><span class="tag">&lt;<span class="name">think</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">think</span>&gt;</span></span><br><span class="line">&#123;&#123; end &#125;&#125;</span><br><span class="line">&#123;&#123;- end -&#125;&#125;</span><br><span class="line">&#123;&#123;- end &#125;&#125;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">PARAMETER stop &lt;｜begin▁of▁sentence｜&gt;</span><br><span class="line">PARAMETER stop &lt;｜end▁of▁sentence｜&gt;</span><br><span class="line">PARAMETER stop &lt;｜User｜&gt;</span><br><span class="line">PARAMETER stop &lt;｜Assistant｜&gt;</span><br></pre></td></tr></table></figure>

<p>After the process was completed, a simple comparison was made with the base mold.  Seems not bad and could be used for the next time.</p>
<p><img src="https://picx.zhimg.com/80/v2-5377bc823e916e5ac303e9626c3d70c6_1440w.png?source=ccfced1a" alt="img"></p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>The pitfalls encountered in this practice were more concentrated on the data and training pipeline rather than the model itself, which also confirmed that “problems outside the model often take more time.”  The overall effect is acceptable.  At least it can bring out the coldness and formulaic stability.  The specific effect will be verified by the HR in the future.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://ayinzhang.github.io/en">YiZhen</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://ayinzhang.github.io/en/2025/12/19/2025-12-19-Simply%20Exploration%20of%20LLM%20PEFT%20Fine-tuning%20and%20Ollama%20Operation/">https://ayinzhang.github.io/en/2025/12/19/2025-12-19-Simply%20Exploration%20of%20LLM%20PEFT%20Fine-tuning%20and%20Ollama%20Operation/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/en/tags/Artificial-intelligence/">Artificial intelligence</a></div><div class="post_share"><div class="social-share" data-image="https://pic1.zhimg.com/v2-71b0fc16e8b2f0e3771e38494b646666_r.jpg?source=172ae18b" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>Sponsor</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/en/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/en/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/en/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/en/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/en/2026/01/07/2026-1-7-Simply%20Exploration%20of%20Unity%20ML-Agents%20Reinforcement%20Learning/" title="Simply Exploration of Unity ML-Agents Reinforcement Learning"><img class="cover" src="https://picx.zhimg.com/v2-42d063eae19380631578c7a1af6acddd_1440w.png?source=ccfced1a" onerror="onerror=null;src='/en/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">Simply Exploration of Unity ML-Agents Reinforcement Learning</div></div></a></div><div class="next-post pull-right"><a href="/en/2025/08/16/2025-8-16-Simply%20Exploration%20of%20Unity%20YooAsset%20+%20HybridCLR%20Hot%20Update/" title="Simply Exploration of Unity YooAsset + HybridCLR Hot Update"><img class="cover" src="https://pic1.zhimg.com/v2-09bfa8f60abc5361104c7584f6df43cd_720w.jpeg?source=d16d100b" onerror="onerror=null;src='/en/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">Simply Exploration of Unity YooAsset + HybridCLR Hot Update</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/en/2026/01/07/2026-1-7-Simply%20Exploration%20of%20Unity%20ML-Agents%20Reinforcement%20Learning/" title="Simply Exploration of Unity ML-Agents Reinforcement Learning"><img class="cover" src="https://picx.zhimg.com/v2-42d063eae19380631578c7a1af6acddd_1440w.png?source=ccfced1a" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-07</div><div class="title">Simply Exploration of Unity ML-Agents Reinforcement Learning</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/en/img/me.jpg" onerror="this.onerror=null;this.src='/en/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">YiZhen</div><div class="author-info__description">End Apocalypse</div></div><div class="card-info-data site-data is-center"><a href="/en/archives/"><div class="headline">Articles</div><div class="length-num">26</div></a><a href="/en/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/en/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ayinzhang"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ayinzhang" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:1242857339@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">It's just a little wind frost</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Written-before"><span class="toc-number">1.</span> <span class="toc-text">Written before</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Preparation"><span class="toc-number">2.</span> <span class="toc-text">Preparation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Preliminary-research"><span class="toc-number">2.1.</span> <span class="toc-text">Preliminary research</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Overall-Architecture"><span class="toc-number">2.2.</span> <span class="toc-text">Overall Architecture</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Practical-Implementation"><span class="toc-number">3.</span> <span class="toc-text">Practical Implementation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Model-Fine-tuning"><span class="toc-number">3.1.</span> <span class="toc-text">Model Fine-tuning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Runtime-Validation"><span class="toc-number">3.2.</span> <span class="toc-text">Runtime Validation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Summary"><span class="toc-number"></span> <span class="toc-text">Summary</span></a></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/en/2026/01/17/2026-1-17-Godot%20Jolt%20Parallel%20Comparison/" title="Godot vs Jolt Parallel Comparison"><img src="https://picx.zhimg.com/v2-d28e53e000188ec10622ace95af2cfcb_1440w.png?source=ccfced1a" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Godot vs Jolt Parallel Comparison"/></a><div class="content"><a class="title" href="/en/2026/01/17/2026-1-17-Godot%20Jolt%20Parallel%20Comparison/" title="Godot vs Jolt Parallel Comparison">Godot vs Jolt Parallel Comparison</a><time datetime="2026-01-16T16:00:00.000Z" title="Created 2026-01-17 00:00:00">2026-01-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/2026/01/15/2026-1-15-Analysis%20of%20Godot%20Physics%20Source%20Code/" title="Analysis of Godot Physics Source Code"><img src="https://picx.zhimg.com/v2-a58a4e744580865dce7d671dfb7ebbb3_1440w.png?source=ccfced1a" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Analysis of Godot Physics Source Code"/></a><div class="content"><a class="title" href="/en/2026/01/15/2026-1-15-Analysis%20of%20Godot%20Physics%20Source%20Code/" title="Analysis of Godot Physics Source Code">Analysis of Godot Physics Source Code</a><time datetime="2026-01-14T16:00:00.000Z" title="Created 2026-01-15 00:00:00">2026-01-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/2026/01/07/2026-1-7-Simply%20Exploration%20of%20Unity%20ML-Agents%20Reinforcement%20Learning/" title="Simply Exploration of Unity ML-Agents Reinforcement Learning"><img src="https://picx.zhimg.com/v2-42d063eae19380631578c7a1af6acddd_1440w.png?source=ccfced1a" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Simply Exploration of Unity ML-Agents Reinforcement Learning"/></a><div class="content"><a class="title" href="/en/2026/01/07/2026-1-7-Simply%20Exploration%20of%20Unity%20ML-Agents%20Reinforcement%20Learning/" title="Simply Exploration of Unity ML-Agents Reinforcement Learning">Simply Exploration of Unity ML-Agents Reinforcement Learning</a><time datetime="2026-01-06T16:00:00.000Z" title="Created 2026-01-07 00:00:00">2026-01-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/2025/12/19/2025-12-19-Simply%20Exploration%20of%20LLM%20PEFT%20Fine-tuning%20and%20Ollama%20Operation/" title="Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation"><img src="https://pic1.zhimg.com/v2-71b0fc16e8b2f0e3771e38494b646666_r.jpg?source=172ae18b" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation"/></a><div class="content"><a class="title" href="/en/2025/12/19/2025-12-19-Simply%20Exploration%20of%20LLM%20PEFT%20Fine-tuning%20and%20Ollama%20Operation/" title="Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation">Simply Exploration of LLM PEFT Fine-tuning and Ollama Operation</a><time datetime="2025-12-18T16:00:00.000Z" title="Created 2025-12-19 00:00:00">2025-12-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/en/2025/08/16/2025-8-16-Simply%20Exploration%20of%20Unity%20YooAsset%20+%20HybridCLR%20Hot%20Update/" title="Simply Exploration of Unity YooAsset + HybridCLR Hot Update"><img src="https://pic1.zhimg.com/v2-09bfa8f60abc5361104c7584f6df43cd_720w.jpeg?source=d16d100b" onerror="this.onerror=null;this.src='/en/img/404.jpg'" alt="Simply Exploration of Unity YooAsset + HybridCLR Hot Update"/></a><div class="content"><a class="title" href="/en/2025/08/16/2025-8-16-Simply%20Exploration%20of%20Unity%20YooAsset%20+%20HybridCLR%20Hot%20Update/" title="Simply Exploration of Unity YooAsset + HybridCLR Hot Update">Simply Exploration of Unity YooAsset + HybridCLR Hot Update</a><time datetime="2025-08-15T16:00:00.000Z" title="Created 2025-08-16 00:00:00">2025-08-16</time></div></div></div></div></div></div></main><footer id="footer" style="background: rgba(1,1,1,0)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2026 By YiZhen</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="translateLink" type="button" title="Toggle Between Chinese And English">EN</button><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/en/js/utils.js?v=4.13.0"></script><script src="/en/js/main.js?v=4.13.0"></script><script src="/en/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(()=>{
  const getGiscusTheme = theme => {
    return theme === 'dark' ? 'dark' : 'light'
  }

  const loadGiscus = () => {
    const config = Object.assign({
      src: 'https://giscus.app/client.js',
      'data-repo': 'ayinzhang/ayinzhang.github.io',
      'data-repo-id': 'R_kgDOKl3Dog',
      'data-category-id': 'DIC_kwDOKl3Dos4CaqXe',
      'data-mapping': 'pathname',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true
    },null)

    const ele = document.createElement('script')
    for (let key in config) {
      ele.setAttribute(key, config[key])
    }
    document.getElementById('giscus-wrap').appendChild(ele)
  }

  const changeGiscusTheme = theme => {
    const sendMessage = message => {
      const iframe = document.querySelector('iframe.giscus-frame')
      if (!iframe) return
      iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app')
    }

    sendMessage({
      setConfig: {
        theme: getGiscusTheme(theme)
      }
    });
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment= loadGiscus
  }
})()</script></div><script data-pjax src="/en/self/btf.js"></script><script data-pjax src="/en/self/tw_en.js"></script><div class="aplayer no-destroy" data-id="8985244058" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="false"> </div><script id="canvas_nest" defer="defer" color="0,0,0" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-show-text.min.js" data-mobile="true" data-text="且行且看,尽力而为,不要害怕,不要后悔" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["link[rel=\"canonical\"]","meta[property=\"og:image\"]","meta[property=\"og:title\"]","meta[property=\"og:url\"]","head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/en/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/en/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/en/live2dw/assets/elica.model.json"},"display":{"superSample":2,"width":200,"height":400,"position":"right","hOffset":20,"vOffset":-130},"mobile":{"show":false,"scale":0.3},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"log":false});</script></body></html>